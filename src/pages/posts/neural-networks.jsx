import * as React from "react";
import { Router, Link } from "wouter";
import 'katex/dist/katex.min.css';
import { InlineMath, BlockMath } from 'react-katex';

export default function Post_NeuralNetworks() {

  return (
    <div className="page">
      <div class="post">
        <h1>Intro to Neural Networks</h1>
        So far we've discussed machine learning algorithms which help with making relatively simple predictions. Both our <Link className="link" href="/posts/linear-regression">linear regression</Link> and <Link className="link" href="/posts/logistic-regression">logistic regressions</Link> algorithms weighted some input features against each other and made a prediction directly from them. We were able to do this because there were relatively clear relationships between features and our prediction. For example, in our discussion of linear regression, when a car's mileage increased, the price decreased. Relatively straightforward -- we were able to model it with a linear equation.<br /><br />
        Now let's discuss a more complex prediction -- facial recognition. It's easy for humans to recognize faces but extremely difficult for a machine to do. A machine just sees a bunch of computer pixels -- it has no knowledge of what a face even looks like. Not to mention the huge diversity in faces -- even basic features such as facial structure vary widely. Add in the fact that faces can be in different positions in a picture, at different rotations, of different sizes, etc. and we have a seemingly-endless array of problems appear.<br /><br />
        If you try to manually create features as we did in our earlier regression articles, you'll soon find that this is near-impossible. For example, how would you tell a computer to identify even a single eye? The eye could be open or shut. It could be different colors and surrounded by skin of different pigments. It could be different sizes. It might appear in slightly different positions on people's faces. If you try to manually tell the computer to look for certain pixels, you'll run into these issues and more. And this is just for a single eye!<br /><br />
        Instead of making a single seemingly-impossible decision, it would be much better to split this up into lots of little decisions. For example, maybe first we just identify the edges in a person's face. At a high level we can do this by measuring the difference in RGB color values of adjacent pixels and mapping out these differences -- a line of pixels which have large color differences is a good indication that we are looking at an edge! As a first step we can identify just these edges.<br /><br />
        Then maybe we notice that certain edges often appear near each other on faces. And so we identify edges that appear in common patterns on faces -- these might indicate parts of cheekbones, parts of a chin, parts of an ear, and so on -- from our edges we are starting to construct parts of facial features.<br /><br />
        Maybe we then look at these parts of facial features and realize some of these parts appear awfully near each other in a lot of faces we've seen in the past. And so we put those parts together and now the shapes of ears, of eyes, of noses, and so on are starting to emerge.<br /><br />
        We can keep going but you get the idea. What we've done is break this problem into a lot of smaller problems, each of which builds upon the work of the last. And it's a lot easier to train machine learning models to make these simple decisions! Maybe we have some simple models learn how to identify edges, some more learn how to stitch those into parts of facial features, even more to learn to build rough facial features out of those parts, and so on.<br /><br />
        <h2>Neurons</h2>
        We call these simple models <b>neurons</b>. Each neuron learns to identify a case or cases of a pattern. For example, maybe one neuron learns to identify one type of edge, another learns to identify a different type of edge, and so on. We divide these neurons up by the problem they are trying to solve -- we call these divisions <b>layers</b>. For example, maybe our first layer of neurons identifies edges, our second layer uses those edges to identify parts of facial features, and so on. Each layer takes the patterns identified from the previous layer, combines them in different ways to create even more complex patterns, and passes these more complex patterns to the next layer. In this way, over many layers, our neurons can work together to identify complex patterns! We call these layers of neurons working together a <b>neural network</b>.<br /><br />
        When a neuron takes in patterns from a previous layer (or from the input features if this is the first layer of neurons), it must decide whether they match the more complex pattern the neuron is trying to identify (and to what degree!). In short, it must make a <b>prediction</b>. How have we made predictions in the past? We first take in each of our features <InlineMath math="x_i"/>, which are either input features (in the case of the first layer) or the patterns from the previous layer. Then we scale the importance of each input feature <InlineMath math="x_i"/> with its input on predicting the more cmplex pattern, which is accomplished by multiplying it by its weight <InlineMath math="\theta_i"/>. As before, each product <InlineMath math="x_i\theta_i"/> represents how much our prediction changes as a result of the feature <InlineMath math="x_i"/>. And again, to calculate the total change in prediction because of our features we add up all the products: <InlineMath math="z = \sum_{i}x_i\theta_i"/>. Change from what? Just as before, we add a "default" prediction by adding a <b>bias term</b> <InlineMath math="b"/>. We add our bias term to our sum to complete our neuron's prediction:
        <BlockMath math="z = \sum_ix_i\theta_i + b"/>
        <h2>Activation Functions</h2>
        Now, there's one small addition we need. Neurons are identifying slightly more complicated patterns than our regression models were. They each take the information from the previous layer and further refine the overall prediction (such as facial detection). To perform this refinement, they must <i>focus</i> on relevant information for refining this overall prediction. Focusing on relevant information means paying less or even no attention to other, less-relevant information.<br /><br />
        To do this, we will take our output <InlineMath math="z = \sum_ix_i\theta_i + b"/> and pass it through a function that allows us to focus on relevant information -- we call such a function an <b>activation function</b>. There are many types of activation functions, and we will explore some more later on. (We've already seen one activation function -- the <Link className="link" href="/posts/logistic-regression">sigmoid function</Link>!) For now though, a good default is the <b>ReLU activation function</b>.<br /><br />
        The ReLU activation function passes important information to the next layers and discards unimportant information. It accomplishes this by leaving positive inputs unchanged and setting negative inputs to 0. It can be written mathematically as shown below:
        <BlockMath math="ReLU(z) = max(0, z)"/>
        If you're wondering what the <tt>max</tt> function means, it simply takes two inputs and returns whichever one is greater. If <InlineMath math="z"/> is positive, then it will be greater than 0 and so will be returned unchanged. And if it is negative, then it will be less than 0 and so the function will return 0. A graph of the ReLU function is shown below:<br /><br />
        <img className="post-image" src="https://cdn.glitch.global/38b66a85-61fb-4fd9-aece-1abd8978751c/relu.png?v=1656569962553" alt="Graph of ReLU function"/><br/><br/>
        When the weights of a neuron with a ReLU activation function are trained, they will be trained to set the output to a negative value if the neuron decides that the information is unimportant (for example, if a certain pattern isn't present), so that it is discarded. In this way, only important information is retained -- this lets the neural network <i>focus</i> on important information and refine its gradually more complex pattern that it is identifying.<br /><br />
        And that concludes our discussion of the basics of neurons and neural networks! In sum, each neuron takes in patterns from neurons in the previous layer and combines them together to form a slightly more complex pattern. In the process, it also focuses on important information and discards unimportant information, allowing it to refine its more complex pattern. It then passes its slightly more complex pattern to neurons in the next layer. And this process continues until, at the end, we've identified a sufficiently complex pattern (such as the general pattern of a face!). In the next section, we will go further into the design of neural networks and how we can streamline their information flow and learning.
        <h2>Exercises</h2>
        <ol>
        </ol>
        <h2>Solutions</h2>
        <ol>
        </ol>
      </div>
    </div>
  );
}
